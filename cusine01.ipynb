{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - clean and balance your data\n",
    "The first task at hand, before starting this project, is to clean and balance your data to get better results.\n",
    "\n",
    "# Delicious Asian and Indian Cuisines \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Imblearn which will enable SMOTE. This is a Scikit-learn package that helps handle imbalanced data when performing classification. (https://imbalanced-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/codespace/.local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.4.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.0/258.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.2 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages you need to import your data and visualize it, also import SMOTE from imblearn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('./cuisines.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes 385 columns indicating all kinds of ingredients in various cuisines from a given set of cuisines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data's shape\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info about this data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "df.cuisine.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning about cusines\n",
    "\n",
    "Show the cuisines in a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as bars by calling barh()\n",
    "\n",
    "df.cuisine.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a finite number of cuisines, but the distribution of data is uneven.\n",
    "# We can fix that! Before doing so, explore a little more.\n",
    "\n",
    "# Find out how much data is available per cuisine and print it out:\n",
    "\n",
    "thai_df = df[(df.cuisine == \"thai\")]\n",
    "japanese_df = df[(df.cuisine == \"japanese\")]\n",
    "chinese_df = df[(df.cuisine == \"chinese\")]\n",
    "indian_df = df[(df.cuisine == \"indian\")]\n",
    "korean_df = df[(df.cuisine == \"korean\")]\n",
    "\n",
    "print(f'thai df: {thai_df.shape}')\n",
    "print(f'japanese df: {japanese_df.shape}')\n",
    "print(f'chinese df: {chinese_df.shape}')\n",
    "print(f'indian df: {indian_df.shape}')\n",
    "print(f'korean df: {korean_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top ingredients by class\n",
    "\n",
    "We can dig deeper into the data and learn what are the typical ingredients per cuisine.\n",
    "We should clean out recurrent data that creates confusion between cuisines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function create_ingredient() in Python to create an ingredient dataframe\n",
    "# This function will start by dropping an unhelpful column and sort through ingredients by their count\n",
    "\n",
    "def create_ingredient_df(df):\n",
    "    # transpose df, drop cuisine and unnamed rows, sum the row to get total for ingredient and add value header to new df\n",
    "    ingredient_df = df.T.drop(['cuisine','Unnamed: 0']).sum(axis=1).to_frame('value')\n",
    "    # drop ingredients that have a 0 sum\n",
    "    ingredient_df = ingredient_df[(ingredient_df.T != 0).any()]\n",
    "    # sort df\n",
    "    ingredient_df = ingredient_df.sort_values(by='value', ascending=False, inplace=False)\n",
    "    return ingredient_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use create_ingredient_df function to get an idea of top ten most popular ingredients by cuisine\n",
    "# Call create_ingredient() and plot it calling barh()\n",
    "\n",
    "thai_ingredient_df = create_ingredient_df(thai_df)\n",
    "thai_ingredient_df.head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_ingredient_df = create_ingredient_df(japanese_df)\n",
    "japanese_ingredient_df.head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_ingredient_df = create_ingredient_df(chinese_df)\n",
    "chinese_ingredient_df.head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_ingredient_df = create_ingredient_df(indian_df)\n",
    "indian_ingredient_df.head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_ingredient_df = create_ingredient_df(korean_df)\n",
    "korean_ingredient_df.head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop very common ingredients (common to all cuisines)\n",
    "They can create confusion between distinct cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone loves rice, garlic and ginger!\n",
    "\n",
    "feature_df= df.drop(['cuisine','Unnamed: 0','rice','garlic','ginger'], axis=1)\n",
    "labels_df = df.cuisine #.unique()\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance data with SMOTE (Synthetic Minority Over-sampling Technique) oversampling to the highest class. Read more here: https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call fit_resample(), this strategy generates new samples by interpolation\n",
    "\n",
    "oversample = SMOTE()\n",
    "transformed_feature_df, transformed_label_df = oversample.fit_resample(feature_df, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By balancing your data, you'll have better results when classifying it. Think about a binary classification.\n",
    "# If most of your data is one class, a ML model is going to predict that class more frequently, just because there is more data for it.\n",
    "# Balancing the data takes any skewed data and helps remove this imbalance.\n",
    "\n",
    "# We can check the numbers of labels per ingredient\n",
    "\n",
    "print(f'new label count: {transformed_label_df.value_counts()}')\n",
    "print(f'old label count: {df.cuisine.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is nice and clean as well as balanced.\n",
    "# The next step is to save the balanced data, including labels and features, into a new dataframe that can be exported into a file\n",
    "\n",
    "transformed_df = pd.concat([transformed_label_df,transformed_feature_df],axis=1, join='outer')\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take one more look at the data using transformed_df.head() and transformed_df.info()\n",
    "\n",
    "transformed_df.head()\n",
    "transformed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.to_csv(\"../../data/cleaned_cuisines.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70b38d7a306a849643e446cd70466270a13445e5987dfa1344ef2b127438fa4d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('3.7')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "70b38d7a306a849643e446cd70466270a13445e5987dfa1344ef2b127438fa4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
